[
  {
    "objectID": "run_alpseq.html",
    "href": "run_alpseq.html",
    "title": "Running alpseq",
    "section": "",
    "text": "This page will teach you how to use alpseq to analyse nanobody panning data! ðŸ¦™"
  },
  {
    "objectID": "run_alpseq.html#introduction",
    "href": "run_alpseq.html#introduction",
    "title": "Running alpseq",
    "section": "",
    "text": "This page will teach you how to use alpseq to analyse nanobody panning data! ðŸ¦™"
  },
  {
    "objectID": "run_alpseq.html#running-the-pipeline",
    "href": "run_alpseq.html#running-the-pipeline",
    "title": "Running alpseq",
    "section": "Running the pipeline",
    "text": "Running the pipeline\n\nClone the repo (git clone https://github.com/kzeglinski/alpseq.git)\nEdit the nextflow.config file to suit your environment (see below for more info).\nMake sure you have nextflow installed on your computer\nRun the pipeline using nextflow run alpseq/main.nf -profile docker or nextflow run alpseq/main.nf -profile singularity depending on which container engine you want to use\n\nThere is also a nice guide on running nextflow pipelines for beginners here\n\nParameters\nOn the command line, you can see a summary of key parameters using nextflow run alpseq/main.nf --help.\nThe most important parameters that you need to set every time (required arguments) are:\n\n--out_dir is the path where output files will be written to. If it doesnâ€™t exist yet, the pipeline will create it\n--fastq_dir is the path where the input fastq files are located\n--sample_sheet is the path to the .csv formatted sample sheet\n\nOther parameters you might sometimes need to change are:\n\n--use_igblast whether to use IgBLAST for nanobody annotation or not (default: true)\n--qc_only whether to only perform quality control of the samples, and skip making a pan report. Turn this on if you are not analysing panning data with rounds (e.g.Â repertoire, or just sequencing unenriched libraries) (default: false)\n\nSome more advanced you shouldnâ€™t need to change often parameters are:\n\n--adapter_r1 and --adapter_r2 the read 1 and read 2 adapters to trim off (default are for Illumina NextSeq)\n--maximum_overlap the maximum overlap of reads 1 and 2, for merging with FLASH. You might need to change this if you have a different sequencing construct design (default: 250)\n--igblast_databases and/or --mb_scripts the paths to the IgBLAST databases and matchbox scripts to use for nanobody annotation. If using a custom organism you may also need to edit the parameter igblast_db_name (default: alpaca) to match your organismâ€™s name\n--template_dir and --extensions_dir and --quaro_base_yaml the paths to the template files used to generate quarto reports. You could change these to create your own custom reports\n--sequence_trim_5p and --sequence_trim_3p are optional sequences to trim off the 5â€™ and 3â€™ when writing out nucleotide sequences. This is useful if, for example, you want to remove bits of the nanobody DNA sequence prior to writing it out (e.g.Â remove his tag) (default: \"\")\n--chunk_size since IgBLAST doesnâ€™t scale well, break samples into chunks for annotation. This will submit a whole bunch of slurm jobs, so you might need to change it if that is a problem for your compute cluster (default: 25000)\n\n\nNextflow config files\nYou can set all of the above parameters on the command line (e.g.Â nextflow run alpseq/main.nf -profile docker --fastq_dir ~/my_files/), although take care that, as for all nextflow pipelines, a single dash is used for nextflow options (e.g.Â -profile docker) and a double dash is used for pipeline parameters (e.g.Â --fastq_dir ~/my_files/).\nHowever, I personally prefer to change these parameters in the nextflow.config file that is contained within the top-level directory of the pipeline. This is handy as you can then copy the config into your output directory to have a record of the parameters you used.\nThe config file also allows you to control other aspects of how nextflow runs this pipeline (for example, using SLURM or AWS). The config file supplied with alpseq has been written to run on WEHIâ€™s Milton HPC, and may not work on your system. You might want to try looking at the nf-core collection of institutional config files to see if they have one for your institute. Alternatively, you could try asking a nextflow expert at your workplace!\nFor more information about writing/editing nextflow config files, take a look at the official nextflow documentation.\n\n\n\nSample sheet\nSample sheets should have the following columns:\n\nsample_num: a sample number (can duplicate samples if e.g.Â the same round 0 is shared across multiple pans)\nlibrary: a string to name the library (just used for naming/labelling)\nantigen: a name for the antigen (just used for naming/labelling)\nround: the round of panning e.g.Â 0, 1, 2, 3, 4\nreplicate: an ID for the replicate NA if no replicates\npanning_id: an ID that groups samples from the same pan (so that a report can contain comparisons of multiple pans)\nreport_id: a name for the report (so you can generate multiple reports for multiple different pans at once)\nr1_file_name: name of the read 1 fastq file\nr2_file_name: name of the read 2 fastq file\n\nFor example, the sample sheet to process the Hanke et al. data would be:\nsample_num,library,antigen,round,replicate,panning_id,report_id,r1_file_name,r2_file_name\nS01,Tyson,covid,0,NA,1,hanke_et_al,round0_read1.fastq.gz,round0_read2.fastq.gz\nS02,Tyson,covid,1,NA,1,hanke_et_al,round1_read1.fastq.gz,round1_read2.fastq.gz\nS03,Tyson,covid,2,NA,1,hanke_et_al,round2_read1.fastq.gz,round2_read2.fastq.gz\n\n\nOutput\nalpseq will output the following:\n\noriginal_annotation_tsv: the .tsv files from either IgBLAST or matchbox\nprocessed_tsv: the .tsv files that have been processed by alpseq (summaries of germline gene composition, tables of clone counts collapsed by CDR3, etc)\nreport: the QC and panning reports generated by alpseq. See the â€˜sample reportsâ€™ tab for examples of these"
  },
  {
    "objectID": "run_alpseq.html#other-useful-stuff",
    "href": "run_alpseq.html#other-useful-stuff",
    "title": "Running alpseq",
    "section": "Other useful stuff",
    "text": "Other useful stuff\n\nSanger mode\nalpseq can be used to annotate sanger sequences with the --sanger_mode parameter. This isnâ€™t really a super recommended workflow, but exists as an option for our collaborators. Use at your own risk!\n\n\nIgBLAST vs matchbox\nThere are two different tools that can be used for annotating nanobodies in alpseq, IgBLAST (default) and matchbox. A comparison/benchmark is included in our preprint, but briefly the tools generate highly similar counts for most CDR3s. IgBLAST is much slower, but outputs a lot more information (according to AIRR specs), while matchbox is a lot faster but outputs just the bare minimum information for analysis (CDR3 and V gene). Choose the method that best suits the info you require and the computing power you have available!"
  },
  {
    "objectID": "alpseqR.html",
    "href": "alpseqR.html",
    "title": "alpseqR",
    "section": "",
    "text": "The alpseqR package contains the various nanobody panning analysis functions used to generate alpseq reports. It is available on github and can be installed in R as follows:\n\nif (!require(\"devtools\")) {\n    install.packages(\"devtools\")\n}\n\ndevtools::install_github(\"kzeglinski/alpseqR\")\n\nThis page will explain how to use alpseqR to perform your own custom analyses."
  },
  {
    "objectID": "alpseqR.html#introduction",
    "href": "alpseqR.html#introduction",
    "title": "alpseqR",
    "section": "",
    "text": "The alpseqR package contains the various nanobody panning analysis functions used to generate alpseq reports. It is available on github and can be installed in R as follows:\n\nif (!require(\"devtools\")) {\n    install.packages(\"devtools\")\n}\n\ndevtools::install_github(\"kzeglinski/alpseqR\")\n\nThis page will explain how to use alpseqR to perform your own custom analyses."
  },
  {
    "objectID": "alpseqR.html#setup",
    "href": "alpseqR.html#setup",
    "title": "alpseqR",
    "section": "Setup",
    "text": "Setup\nhow to get the files that the package needs, read them in"
  },
  {
    "objectID": "alpseqR.html#alpseqr-functions",
    "href": "alpseqR.html#alpseqr-functions",
    "title": "alpseqR",
    "section": "alpseqR functions",
    "text": "alpseqR functions\n\nCount matrix preparation\n\n\nClustering\n\n\nVisualisations\n\n\nTop 100 selection\n\n\nComparisons"
  },
  {
    "objectID": "alpseqR.html#example-analysis-workflow",
    "href": "alpseqR.html#example-analysis-workflow",
    "title": "alpseqR",
    "section": "Example analysis workflow",
    "text": "Example analysis workflow"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "Welcome to the alpseq documentation website! This page aims to explain how to run the alpseq nextflow pipeline, as well as the companion alpseqR R package."
  },
  {
    "objectID": "index.html#useful-links",
    "href": "index.html#useful-links",
    "title": "Home",
    "section": "Useful links",
    "text": "Useful links\n\nThe alpseq preprint\nThe example data used to develop alpseq\nAnother useful public dataset and its corresponding paper"
  },
  {
    "objectID": "sample_reports.html",
    "href": "sample_reports.html",
    "title": "Sample reports",
    "section": "",
    "text": "This page contains samples of the reports generated by alpseq. The data from these reports comes from Hanke et al."
  },
  {
    "objectID": "sample_reports.html#qc-report",
    "href": "sample_reports.html#qc-report",
    "title": "Sample reports",
    "section": "QC report",
    "text": "QC report"
  },
  {
    "objectID": "sample_reports.html#pan-report",
    "href": "sample_reports.html#pan-report",
    "title": "Sample reports",
    "section": "Pan report",
    "text": "Pan report"
  },
  {
    "objectID": "custom_reference.html",
    "href": "custom_reference.html",
    "title": "Using alpseq with a custom reference",
    "section": "",
    "text": "alpseq comes with a built-in alpaca reference, built from IMGT sequences. This reference is used by both IgBLAST and matchbox, the two software we use for nanobody annotation. To use alpseq with your own custom references you just need to build your own IgBLAST database (matchbox uses one of the files in this database for its annotation process).\nThe IgBLAST documentation has a short guide here, but below we will describe the process in more detail.\nThere are four steps:"
  },
  {
    "objectID": "custom_reference.html#building-the-database",
    "href": "custom_reference.html#building-the-database",
    "title": "Using alpseq with a custom reference",
    "section": "Building the database",
    "text": "Building the database\nBefore you start, make sure you have the correct V/D/J germline files. This is explained in the IgBLAST documentation:\n\nTo search IMGT germline sequences, you need to download them from IMGT web site (http://www.imgt.org/vquest/refseqh.html#VQUEST ). You need to download all V, D and J sequences for whatever organisms you are interested in. Combine all V, all D and all J sequences, respectively, into separate files (i.e., one file for all V sequences, one for all D sequences and one file all for J sequences). After you have downloaded the sequences, invoke our utility tool edit_imgt_file.pl (in the bin directory in the IgBlast release package) to process these sequences (i.e., to change the long IMGT definition lines to germline gene names only). For example:\nbin/edit_imgt_file.pl imgt_file &gt; my_seq_file\n\nNote: alpseq expects the files to be named like â€˜imgt_{ORGANISM}_ighvâ€™ and â€˜imgt_{ORGANISM}_ighdâ€™, etc so please follow this naming convention or you will need to manually edit the paths in the igblast.nf and/or matchbox_annotate.nf scripts.\n\nCreating the V gene annotation file\nThis file annotates the germline V genes. It should be located at the path: internal_data/alpaca/alpaca.ndm.imgt (where you replace alpaca with the name of the organism you are planning to use).\nIt should be in a tab-separated format with the following columns:\nIGHV1-18*01     1  75  76  99  100     150     151     174     175     288     VH  0\nUsing this forum post, my best guess at what the numbers mean is:\n\ncolumn 1: allele name (clean)\ncolumn 2: FR1 start\ncolumn 3: FR1 end\ncolumn 4: CDR1 start\ncolumn 5: CDR1 end\ncolumn 6: FR2 start\ncolumn 7: FR2 end\ncolumn 8: CDR2 start\ncolumn 9: CDR2 end\ncolumn 10: FR3 start\ncolumn 11: FR3 end\ncolumn 12: gene type (VH or VK or VL)\ncolumn 13: not sure? but usually seems to be zero in the human one\n\nBest way I can see to get these numbers is copy paste the sequence into IMGT/V-QUEST and scroll down to the bottom for the annotations. Then, manually enter them into the table.\n\n\nCreating the V gene database\nNext, you need to build a database for just the V genes. You can do this by using the makeblastdb tool (included in IgBLAST and BLAST software), on the cleaned V gene file as shown in the IgBLAST documentation:\nbin/makeblastdb -parse_seqids -dbtype nucl -in my_seq_file\n\n\nCreating the auxiliary file\nThe IgBLAST docs instruct us to â€˜supply a file that has information such as CDR3 stop for germline J genesâ€™. It has some that look like this (example shown is optional_file/human_gl.aux):\n# The chain type, first coding frame start position, chain type, CDR3 stop.\n#positions are 0-based\n\nIGHJ1*01        0   JH  17\nIGHJ1P*01       2   JH\nIGHJ2*01        1   JH  18\nIGHJ2P*01       0   JH\nIGHJ3*01        1   JH  15\nIGHJ3*02        1   JH  15\nIGHJ3P*01       0   JH\nIGHJ4*01        2   JH  13\nIGHJ4*02        2   JH  13\nIGHJ4*03        2   JH  13\nIGHJ5*01        2   JH  16\nIGHJ5*02        2   JH  16\nIGHJ6*01        2   JH  28\nIGHJ6*02        2   JH  28\nIGHJ6*03        2   JH  28\nIGHJ6*04        2   JH  28\nAccording to the IgBLAST documentation, the columns are\n\nAllele name\nGermline J gene coding frame start position (position is 0-based)\nJ gene type (JH, JK, JL)\nThe CDR3 end position for each sequence in the germline J sequence database\n\nWe can again manually construct this using IMGT/V-QUEST. It wonâ€™t work on just the J genes by themselves, so we can construct an artificial Nb sequence to find out this information. Using human IGHJ2*01 as an example:\nPaste IGHV1-18*02, IGHD1-14*01 and IGHJ2*01 together and am looking to recreate this line: IGHJ2*01        1    JH  18\nI think that IMGT/V-QUEST is 1-based not 0-based and thatâ€™s why things arenâ€™t quite lining up like itâ€™s saying codon_start=2 but above itâ€™s 1, and when you line up the CDR3 with the J gene, it ends at position 19 not 18.\nI double checked with a couple of other J genes and this theory seems to be correct. So basically to get column 2, just look at the J region codon_start and minus 1. IMPORTANT: this only works if the sequence is in frame. so, need to check whether it is and if not then add some Nâ€™s after the D gene to bring it back into frame\nTo get column 4, line up the CDR3 nucleotide sequence with the J gene and see which position it ends at (minus 1/ensure you are using zero based positions)\nFollowing these steps I was able to make the auxiliary file for alpaca that is included in alpseq:\n# The allele, first coding frame start position, chain type, CDR3 stop.\n# positions are 0-based\n\nIGHJ1*01    2   JH  13\nIGHJ2*01    2   JH  19\nIGHJ3*01    1   JH  15\nIGHJ4*01    2   JH  13\nIGHJ5*01    2   JH  16\nIGHJ6*01    2   JH  13\nIGHJ7*01    2   JH  19\nIf you have an understanding of how to do this properly let me know, I would love to learn!\n\n\nCreating the V/D/J germline databases\nThese should be located in the databases/ folder. Essentially, copy your cleaned V/D/J germline reference files into here and run makeblastdb as for the V gene database before.\n\n\nWhat to do if you get the dreaded â€˜BLAST query/options errorâ€™ message\nOnce youâ€™ve done these steps, try testing a random sequence with the IgBLAST command line tool. You might encounter this error message: BLAST query/options error: Germline annotation database alpaca/alpaca_V could not be found in [internal_data] directory. Please refer to the BLAST+ user manual.\nSome tips to fix this:\n\nMake sure you didnâ€™t forget to export the environment variables (IGDATA, with absolute path pointing to the folder that contains internal_data. In my case it was: /stornext/General/data/user_managed/grpu_mritchie_1/kathleen/igblast/igdata/ and you also need IGBLASTDB which is the folder with all the databases you search. Mine was: /stornext/General/data/user_managed/grpu_mritchie_1/kathleen/igblast/databases)\nBefore making the database, try having extracted the contents of the taxonomy database (ftp://ftp.ncbi.nlm.nih.gov/blast/db/taxdb.tar.gz) into the same directory. Not sure why it works, but I found a seqanswers post about the same error message (just for a regular BLAST database) and this was suggested as a fix (the post is at https://www.seqanswers.com/forum/bioinformatics/bioinformatics-aa/29829-deploying-a-local-version-of-blast-having-issues)\nOnce youâ€™ve made the database, check with blastdbcheck -dir . (I believe this comes with the actual BLAST program, not IgBLAST) to make sure itâ€™s all good.\n\nFollowing this procedure on not only the germline V gene database in internal_data but also the normal database in the IGBLASTDB path fixed the next error message I got: Error: mdb_dbi_open: MDB_NOTFOUND: No matching key/data pair found"
  },
  {
    "objectID": "custom_reference.html#running-alpseq-with-the-custom-organismdatabase",
    "href": "custom_reference.html#running-alpseq-with-the-custom-organismdatabase",
    "title": "Using alpseq with a custom reference",
    "section": "Running alpseq with the custom organism/database",
    "text": "Running alpseq with the custom organism/database\nOnce youâ€™ve followed these steps and confirmed it is working on the command line, you can try using the custom database with alpseq. Youâ€™ll need to set the following parameters: igblast_databases (the path to where the IgBLAST databases are) and igblast_db_name (the name of the custom organism)."
  }
]