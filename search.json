[
  {
    "objectID": "sample_reports.html",
    "href": "sample_reports.html",
    "title": "Sample reports",
    "section": "",
    "text": "This page contains samples of the reports generated by alpseq. The data from these reports comes from Hanke et al."
  },
  {
    "objectID": "sample_reports.html#qc-report",
    "href": "sample_reports.html#qc-report",
    "title": "Sample reports",
    "section": "QC report",
    "text": "QC report"
  },
  {
    "objectID": "sample_reports.html#pan-report",
    "href": "sample_reports.html#pan-report",
    "title": "Sample reports",
    "section": "Pan report",
    "text": "Pan report"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "Welcome to the alpseq documentation website! This page aims to explain how to run the alpseq nextflow pipeline, as well as the companion alpseqR R package."
  },
  {
    "objectID": "index.html#useful-links",
    "href": "index.html#useful-links",
    "title": "Home",
    "section": "Useful links",
    "text": "Useful links\n\nThe alpseq preprint\nThe example data used to develop alpseq\nAnother useful public dataset and its corresponding paper"
  },
  {
    "objectID": "alpseqR.html",
    "href": "alpseqR.html",
    "title": "alpseqR",
    "section": "",
    "text": "The alpseqR package contains the various nanobody panning analysis functions used to generate alpseq reports. It is available on github and can be installed in R as follows:\n\nif (!require(\"devtools\")) {\n    install.packages(\"devtools\")\n}\n\ndevtools::install_github(\"kzeglinski/alpseqR\")\n\nThis page will explain how to use alpseqR to perform your own custom analyses."
  },
  {
    "objectID": "alpseqR.html#introduction",
    "href": "alpseqR.html#introduction",
    "title": "alpseqR",
    "section": "",
    "text": "The alpseqR package contains the various nanobody panning analysis functions used to generate alpseq reports. It is available on github and can be installed in R as follows:\n\nif (!require(\"devtools\")) {\n    install.packages(\"devtools\")\n}\n\ndevtools::install_github(\"kzeglinski/alpseqR\")\n\nThis page will explain how to use alpseqR to perform your own custom analyses."
  },
  {
    "objectID": "alpseqR.html#setup",
    "href": "alpseqR.html#setup",
    "title": "alpseqR",
    "section": "Setup",
    "text": "Setup\nhow to get the files that the package needs, read them in"
  },
  {
    "objectID": "alpseqR.html#alpseqr-functions",
    "href": "alpseqR.html#alpseqr-functions",
    "title": "alpseqR",
    "section": "alpseqR functions",
    "text": "alpseqR functions\n\nCount matrix preparation\n\n\nClustering\n\n\nVisualisations\n\n\nTop 100 selection\n\n\nComparisons"
  },
  {
    "objectID": "alpseqR.html#example-analysis-workflow",
    "href": "alpseqR.html#example-analysis-workflow",
    "title": "alpseqR",
    "section": "Example analysis workflow",
    "text": "Example analysis workflow"
  },
  {
    "objectID": "run_alpseq.html",
    "href": "run_alpseq.html",
    "title": "Running alpseq",
    "section": "",
    "text": "This page will teach you how to use alpseq to analyse nanobody panning data! ðŸ¦™"
  },
  {
    "objectID": "run_alpseq.html#introduction",
    "href": "run_alpseq.html#introduction",
    "title": "Running alpseq",
    "section": "",
    "text": "This page will teach you how to use alpseq to analyse nanobody panning data! ðŸ¦™"
  },
  {
    "objectID": "run_alpseq.html#running-the-pipeline",
    "href": "run_alpseq.html#running-the-pipeline",
    "title": "Running alpseq",
    "section": "Running the pipeline",
    "text": "Running the pipeline\n\nClone the repo (git clone https://github.com/kzeglinski/alpseq.git)\nEdit the nextflow.config file to suit your environment (see below for more info).\nMake sure you have nextflow installed on your computer\nRun the pipeline using nextflow run alpseq/main.nf -profile docker or nextflow run alpseq/main.nf -profile singularity depending on which container engine you want to use\n\nThere is also a nice guide on running nextflow pipelines for beginners here\n\nParameters\nOn the command line, you can see a summary of key parameters using nextflow run alpseq/main.nf --help.\nThe most important parameters that you need to set every time (required arguments) are:\n\n--out_dir is the path where output files will be written to. If it doesnâ€™t exist yet, the pipeline will create it\n--fastq_dir is the path where the input fastq files are located\n--sample_sheet is the path to the .csv formatted sample sheet\n\nOther parameters you might sometimes need to change are:\n\n--use_igblast whether to use IgBLAST for nanobody annotation or not (default: true)\n--qc_only whether to only perform quality control of the samples, and skip making a pan report. Turn this on if you are not analysing panning data with rounds (e.g.Â repertoire, or just sequencing unenriched libraries) (default: false)\n\nSome more advanced you shouldnâ€™t need to change often parameters are:\n\n--adapter_r1 and --adapter_r2 the read 1 and read 2 adapters to trim off (default are for Illumina NextSeq)\n--maximum_overlap the maximum overlap of reads 1 and 2, for merging with FLASH. You might need to change this if you have a different sequencing construct design (default: 250)\n--igblast_databases and/or --mb_scripts the paths to the IgBLAST databases and matchbox scripts to use for nanobody annotation\n--template_dir and --extensions_dir and --quaro_base_yaml the paths to the template files used to generate quarto reports. You could change these to create your own custom reports\n--sequence_trim_5p and --sequence_trim_3p are optional sequences to trim off the 5â€™ and 3â€™ when writing out nucleotide sequences. This is useful if, for example, you want to remove bits of the nanobody DNA sequence prior to writing it out (e.g.Â remove his tag) (default: \"\")\n--chunk_size since IgBLAST doesnâ€™t scale well, break samples into chunks for annotation. This will submit a whole bunch of slurm jobs, so you might need to change it if that is a problem for your compute cluster (default: 25000)\n\n\nNextflow config files\nYou can set all of the above parameters on the command line (e.g.Â nextflow run alpseq/main.nf -profile docker --fastq_dir ~/my_files/), although take care that, as for all nextflow pipelines, a single dash is used for nextflow options (e.g.Â -profile docker) and a double dash is used for pipeline parameters (e.g.Â --fastq_dir ~/my_files/).\nHowever, I personally prefer to change these parameters in the nextflow.config file that is contained within the top-level directory of the pipeline. This is handy as you can then copy the config into your output directory to have a record of the parameters you used.\nThe config file also allows you to control other aspects of how nextflow runs this pipeline (for example, using SLURM or AWS). The config file supplied with alpseq has been written to run on WEHIâ€™s Milton HPC, and may not work on your system. You might want to try looking at the nf-core collection of institutional config files to see if they have one for your institute. Alternatively, you could try asking a nextflow expert at your workplace!\nFor more information about writing/editing nextflow config files, take a look at the official nextflow documentation.\n\n\n\nSample sheet\nSample sheets should have the following columns:\n\nsample_num: a sample number (can duplicate samples if e.g.Â the same round 0 is shared across multiple pans)\nlibrary: a string to name the library (just used for naming/labelling)\nantigen: a name for the antigen (just used for naming/labelling)\nround: the round of panning e.g.Â 0, 1, 2, 3, 4\nreplicate: an ID for the replicate NA if no replicates\npanning_id: an ID that groups samples from the same pan (so that a report can contain comparisons of multiple pans)\nreport_id: a name for the report (so you can generate multiple reports for multiple different pans at once)\nr1_file_name: name of the read 1 fastq file\nr2_file_name: name of the read 2 fastq file\n\nFor example, the sample sheet to process the Hanke et al. data would be:\nsample_num,library,antigen,round,replicate,panning_id,report_id,r1_file_name,r2_file_name\nS01,Tyson,covid,0,NA,1,hanke_et_al,round0_read1.fastq.gz,round0_read2.fastq.gz\nS02,Tyson,covid,1,NA,1,hanke_et_al,round1_read1.fastq.gz,round1_read2.fastq.gz\nS03,Tyson,covid,2,NA,1,hanke_et_al,round2_read1.fastq.gz,round2_read2.fastq.gz\n\n\nOutput\nalpseq will output the following:\n\noriginal_annotation_tsv: the .tsv files from either IgBLAST or matchbox\nprocessed_tsv: the .tsv files that have been processed by alpseq (summaries of germline gene composition, tables of clone counts collapsed by CDR3, etc)\nreport: the QC and panning reports generated by alpseq. See the â€˜sample reportsâ€™ tab for examples of these"
  },
  {
    "objectID": "run_alpseq.html#other-useful-stuff",
    "href": "run_alpseq.html#other-useful-stuff",
    "title": "Running alpseq",
    "section": "Other useful stuff",
    "text": "Other useful stuff\n\nSanger mode\nalpseq can be used to annotate sanger sequences with the --sanger_mode parameter. This isnâ€™t really a super recommended workflow, but exists as an option for our collaborators. Use at your own risk!\n\n\nIgBLAST vs matchbox\nThere are two different tools that can be used for annotating nanobodies in alpseq, IgBLAST (default) and matchbox. A comparison/benchmark is included in our preprint, but briefly the tools generate highly similar counts for most CDR3s. IgBLAST is much slower, but outputs a lot more information (according to AIRR specs), while matchbox is a lot faster but outputs just the bare minimum information for analysis (CDR3 and V gene). Choose the method that best suits the info you require and the computing power you have available!"
  }
]